# Confluent Cloud connection information
# Do not include 'https://' in the bootstrap URL
bootstrap.servers=<<CONFLUENT CLOUD BOOTSTRAP SERVER URL>>
security.protocol=SASL_SSL
sasl.mechanism=PLAIN
sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username='<<CLUSTER API KEY>>' password='<<CLUSTER API SECRET>>';
# Schema Registroy connection information
schema.registry.url=<<SCHEMA REGISTRY BOOTSTRAP URL>>
basic.auth.credentials.source=USER_INFO
schema.registry.basic.auth.user.info=<<SCHEMA REGISTRY API KEY>>:<<SCHEMA REGISTRY API SECRET>>
key.serializer=org.apache.kafka.common.serialization.StringSerializer
value.serializer=io.confluent.kafka.serializers.KafkaAvroSerializer
client.dns.lookup=use_all_dns_ips
# Best practice for higher availability in Apache Kafka clients prior to 3.0
session.timeout.ms=45000
# Best practice for Kafka producer to prevent data loss
acks=all
# NOTE: If using the provided included TF scripts to build a cluster the 
# Consumer ID MUST start wtih 'consumer' or else a permission error will occur
group.id=consumer-java-test

# Misc variables
topic.name=testing-java