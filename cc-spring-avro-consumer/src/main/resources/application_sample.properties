# Confluent Cloud connection parameters
spring.kafka.bootstrap-servers=<<CONFLUENT CLOUD BOOTSTRAP SERVER URL>>
spring.kafka.properties.ssl.endpoint.identification.mechanism=https
spring.kafka.properties.sasl.mechanism=PLAIN
spring.kafka.properties.request.timeout.ms=20000
spring.kafka.properties.retry.backoff.ms=500
spring.kafka.properties.sasl.jaas.config: org.apache.kafka.common.security.plain.PlainLoginModule required username="<<CLUSTER API KEY>>" password="<<CLUSTER API SECRET>>";
spring.kafka.properties.security.protocol: SASL_SSL
# CCloud Schema Registry Connection parameters
spring.kafka.properties.schema.registry.url: <<SCHEMA REGISTRY BOOTSTRAP URL>>
spring.kafka.properties.basic.auth.credentials.source: USER_INFO
spring.kafka.properties.schema.registry.basic.auth.user.info: <<SR API KEY>>:<<SR API SECRET>>
# Consumer parameters
# NOTE: This MUST start with "consumer" to comply with the RBAC setup in the cluster
spring.kafka.consumer.group-id=consumer-spring
spring.kafka.consumer.auto-offset-reset: earliest
spring.kafka.consumer.key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
# Misc parameters
# Port has been changed so consumer can run at the same time as spring boot producer
app.topic.name: test-spring
server.port=8081